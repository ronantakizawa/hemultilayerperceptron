{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f564d30d",
      "metadata": {
        "id": "f564d30d"
      },
      "source": [
        "# Simple Perceptron Model with Homomorphic Encryption\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Perceptron (Without Encryption)"
      ],
      "metadata": {
        "id": "oofVQdf58inF"
      },
      "id": "oofVQdf58inF"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "b90afb3a",
      "metadata": {
        "id": "b90afb3a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28fd92f3",
      "metadata": {
        "id": "28fd92f3"
      },
      "source": [
        "## Define the Perceptron Model\n",
        "We start by defining the Perceptron class, which includes initializing weights, forward pass, and weight update methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "81241f2c",
      "metadata": {
        "id": "81241f2c"
      },
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.1, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.activation_func = self._unit_step_func\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                y_predicted = self.activation_func(linear_output)\n",
        "                update = self.lr * (y[idx] - y_predicted)\n",
        "                self.weights += update * x_i\n",
        "                self.bias += update\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self.activation_func(linear_output)\n",
        "        return y_predicted\n",
        "\n",
        "    def _unit_step_func(self, x):\n",
        "        return np.where(x > 0, 1, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "411ee5f5",
      "metadata": {
        "id": "411ee5f5"
      },
      "source": [
        "## Load Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "7f45e803",
      "metadata": {
        "id": "7f45e803"
      },
      "outputs": [],
      "source": [
        "iris = datasets.load_iris()\n",
        "x = iris.data\n",
        "y = iris.target\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_binary_class = (y == 0) | (y == 1)\n",
        "x = x[is_binary_class]\n",
        "y = y[is_binary_class]"
      ],
      "metadata": {
        "id": "XIDAjVpBi44i"
      },
      "id": "XIDAjVpBi44i",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=123)"
      ],
      "metadata": {
        "id": "jfIpyeksi9__"
      },
      "id": "jfIpyeksi9__",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8615340f",
      "metadata": {
        "id": "8615340f"
      },
      "source": [
        "## Train the Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "2af26077",
      "metadata": {
        "id": "2af26077"
      },
      "outputs": [],
      "source": [
        "p = Perceptron(learning_rate=0.01, n_iters=100)\n",
        "p.fit(x_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8b50b3c",
      "metadata": {
        "id": "b8b50b3c"
      },
      "source": [
        "## Evaluate the Model\n",
        "We can now test the trained model with the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "27cec743",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27cec743",
        "outputId": "2fad5a48-d8e8-4e2f-edf2-2299158e0fb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model predictions: [0 1 1 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0]\n",
            "Actual labels: [0 1 1 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "predictions = p.predict(x_test)\n",
        "print(\"Model predictions:\", predictions)\n",
        "print(\"Actual labels:\", y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy = np.mean(predictions == y_test)\n",
        "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJa2b5Q95ehU",
        "outputId": "30ddccb0-079f-42ad-fd3f-fd8dfa3112be"
      },
      "id": "jJa2b5Q95ehU",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tu8pcnFn8rVK"
      },
      "id": "tu8pcnFn8rVK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Perceptron (With Encryption)"
      ],
      "metadata": {
        "id": "sLF7lkVk8twR"
      },
      "id": "sLF7lkVk8twR"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tenseal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj5mRgb_8Zu1",
        "outputId": "f2757516-483b-4c51-ea02-b6467a1a4407"
      },
      "id": "Lj5mRgb_8Zu1",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tenseal in /usr/local/lib/python3.10/dist-packages (0.3.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a context for the CKKS scheme\n",
        "import tenseal as ts\n",
        "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree=8192, coeff_mod_bit_sizes=[60, 40, 40, 60])\n",
        "context.global_scale = 2**40\n",
        "context.generate_galois_keys()"
      ],
      "metadata": {
        "id": "4eGleYuF88f0"
      },
      "id": "4eGleYuF88f0",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncryptedPerceptron:\n",
        "    def __init__(self, context, learning_rate=0.1, n_iters=1000, n_features=None):\n",
        "        self.context = context\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.n_features = n_features  # Number of features\n",
        "        self.activation_func = self._unit_step_func\n",
        "        self.weights = ts.ckks_vector(context, np.zeros(n_features))\n",
        "        self.bias = ts.ckks_vector(context, [0])\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        y_ = np.array([1 if i > 0 else 0 for i in y])\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, encrypted_x_i in enumerate(X):\n",
        "                linear_output = encrypted_x_i.dot(self.weights) + self.bias\n",
        "                y_predicted = self.activation_func(linear_output.decrypt())  # Decrypt on secure server\n",
        "\n",
        "                update = self.lr * (y_[idx] - y_predicted)\n",
        "                update_vector = update * np.array(encrypted_x_i.decrypt())  # Ensure the operation is on numpy array\n",
        "                self.weights += ts.ckks_vector(self.context, update_vector)\n",
        "                self.bias += ts.ckks_vector(self.context, [update])\n",
        "\n",
        "    def predict(self, X):\n",
        "        results = []\n",
        "        for encrypted_x_i in X:\n",
        "            linear_output = encrypted_x_i.dot(self.weights) + self.bias\n",
        "            decrypted_output = linear_output.decrypt()  # Ensure decryption before the activation function\n",
        "            y_predicted = self.activation_func(decrypted_output)\n",
        "            results.append(y_predicted)\n",
        "        return results\n",
        "\n",
        "    def _unit_step_func(self, x):\n",
        "        aggregate = sum(x)  # Sum up the decrypted list to get a single scalar value\n",
        "        return 1 if aggregate > 0 else 0\n"
      ],
      "metadata": {
        "id": "l5OniuXN9Bmt"
      },
      "id": "l5OniuXN9Bmt",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_encrypted = [ts.ckks_vector(context, x) for x in x_train]\n",
        "x_test_encrypted = [ts.ckks_vector(context, x) for x in x_test]"
      ],
      "metadata": {
        "id": "7IMSvCOW9f3_"
      },
      "id": "7IMSvCOW9f3_",
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = EncryptedPerceptron(context, learning_rate=0.1, n_iters=100, n_features=4)\n",
        "p.fit(x_train_encrypted, y_train)\n",
        "#Takes about 5 minutes to train"
      ],
      "metadata": {
        "id": "jBFZy3pr-J6e"
      },
      "id": "jBFZy3pr-J6e",
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = p.predict(x_test_encrypted)\n",
        "print(\"Model predictions:\", predictions)\n",
        "print(\"Actual labels:\", y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV6tUQCG-T9s",
        "outputId": "11c17a6c-b9fa-40ad-e504-7c4f3904c932"
      },
      "id": "bV6tUQCG-T9s",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model predictions: [0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "Actual labels: [0 1 1 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy = np.mean(predictions == y_test)\n",
        "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCsUhlpe_09w",
        "outputId": "3fdc7ff1-e82d-41b1-8a57-4ef5a09e6776"
      },
      "id": "kCsUhlpe_09w",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 100.00%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}