{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f564d30d",
      "metadata": {
        "id": "f564d30d"
      },
      "source": [
        "# Simple Neural Network Model with Homomorphic Encryption\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Neural Network (Without Encryption)"
      ],
      "metadata": {
        "id": "oofVQdf58inF"
      },
      "id": "oofVQdf58inF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b90afb3a",
      "metadata": {
        "id": "b90afb3a"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28fd92f3",
      "metadata": {
        "id": "28fd92f3"
      },
      "source": [
        "## Define the Perceptron Model\n",
        "We start by defining the Perceptron class, which includes initializing weights, forward pass, and weight update methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81241f2c",
      "metadata": {
        "id": "81241f2c"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.1, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.activation_func = self._unit_step_func\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "        y_ = np.array([1 if i > 0 else 0 for i in y])\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                y_predicted = self.activation_func(linear_output)\n",
        "                update = self.lr * (y_[idx] - y_predicted)\n",
        "                self.weights += update * x_i\n",
        "                self.bias += update\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self.activation_func(linear_output)\n",
        "        return y_predicted\n",
        "\n",
        "    def _unit_step_func(self, x):\n",
        "        return np.where(x > 0, 1, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "411ee5f5",
      "metadata": {
        "id": "411ee5f5"
      },
      "source": [
        "## Create an Expanded Synthetic Dataset\n",
        "Here, we'll create a larger dataset for our perceptron to classify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7f45e803",
      "metadata": {
        "id": "7f45e803",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbcbc82e-da0a-4893-80f9-2e89aa80474e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 0 0 0 0 1 0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a synthetic dataset with more complexity\n",
        "np.random.seed(0)\n",
        "n_samples = 100\n",
        "n_features = 10\n",
        "\n",
        "X = np.random.randint(0, 2, size=(n_samples, n_features))\n",
        "y = np.random.randint(0, 2, size=n_samples)  # Random binary labels\n",
        "\n",
        "# Adjust the labels to depend on more complex logic (e.g., majority of the first three features)\n",
        "y = (np.sum(X[:, :3], axis=1) > 1).astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n",
        "print(X_train[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8615340f",
      "metadata": {
        "id": "8615340f"
      },
      "source": [
        "## Train the Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2af26077",
      "metadata": {
        "id": "2af26077"
      },
      "outputs": [],
      "source": [
        "\n",
        "p = Perceptron(learning_rate=0.1, n_iters=100)\n",
        "p.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8b50b3c",
      "metadata": {
        "id": "b8b50b3c"
      },
      "source": [
        "## Evaluate the Model\n",
        "We can now test the trained model with the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "27cec743",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27cec743",
        "outputId": "5b552804-5ab3-445a-d134-a446f422d3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model predictions: [0 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
            "Actual labels: [0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "predictions = p.predict(X_test)\n",
        "print(\"Model predictions:\", predictions)\n",
        "print(\"Actual labels:\", y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy = np.mean(predictions == y_test)\n",
        "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJa2b5Q95ehU",
        "outputId": "0f1e14e4-14d0-44dd-938d-6049ed14dd55"
      },
      "id": "jJa2b5Q95ehU",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 84.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tu8pcnFn8rVK"
      },
      "id": "tu8pcnFn8rVK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Neural Network (With Encryption)"
      ],
      "metadata": {
        "id": "sLF7lkVk8twR"
      },
      "id": "sLF7lkVk8twR"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tenseal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj5mRgb_8Zu1",
        "outputId": "51ea6dc4-36e1-424c-a2cd-806827e39259"
      },
      "id": "Lj5mRgb_8Zu1",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tenseal\n",
            "  Using cached tenseal-0.3.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "Installing collected packages: tenseal\n",
            "Successfully installed tenseal-0.3.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a context for the CKKS scheme\n",
        "import tenseal as ts\n",
        "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree=8192, coeff_mod_bit_sizes=[60, 40, 40, 60])\n",
        "context.global_scale = 2**40\n",
        "context.generate_galois_keys()"
      ],
      "metadata": {
        "id": "4eGleYuF88f0"
      },
      "id": "4eGleYuF88f0",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncryptedPerceptron:\n",
        "    def __init__(self, context, learning_rate=0.1, n_iters=1000, n_features=None):\n",
        "        self.context = context\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.n_features = n_features  # Number of features\n",
        "        self.activation_func = self._unit_step_func\n",
        "        self.weights = ts.ckks_vector(context, np.zeros(n_features))\n",
        "        self.bias = ts.ckks_vector(context, [0])\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        y_ = np.array([1 if i > 0 else 0 for i in y])\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, encrypted_x_i in enumerate(X):\n",
        "                linear_output = encrypted_x_i.dot(self.weights) + self.bias\n",
        "                y_predicted = self.activation_func(linear_output.decrypt())  # Decrypt on secure server\n",
        "\n",
        "                update = self.lr * (y_[idx] - y_predicted)\n",
        "                update_vector = update * np.array(encrypted_x_i.decrypt())  # Ensure the operation is on numpy array\n",
        "                self.weights += ts.ckks_vector(self.context, update_vector)\n",
        "                self.bias += ts.ckks_vector(self.context, [update])\n",
        "\n",
        "    def predict(self, X):\n",
        "        results = []\n",
        "        for encrypted_x_i in X:\n",
        "            linear_output = encrypted_x_i.dot(self.weights) + self.bias\n",
        "            decrypted_output = linear_output.decrypt()  # Ensure decryption before the activation function\n",
        "            y_predicted = self.activation_func(decrypted_output)\n",
        "            results.append(y_predicted)\n",
        "        return results\n",
        "\n",
        "    def _unit_step_func(self, x):\n",
        "        aggregate = sum(x)  # Sum up the decrypted list to get a single scalar value\n",
        "        return 1 if aggregate > 0 else 0\n"
      ],
      "metadata": {
        "id": "l5OniuXN9Bmt"
      },
      "id": "l5OniuXN9Bmt",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a synthetic dataset with more complexity\n",
        "np.random.seed(0)\n",
        "n_samples = 100\n",
        "n_features = 10\n",
        "\n",
        "X = np.random.randint(0, 2, size=(n_samples, n_features))\n",
        "y = np.random.randint(0, 2, size=n_samples)  # Random binary labels\n",
        "\n",
        "# Adjust the labels to depend on more complex logic (e.g., majority of the first three features)\n",
        "y = (np.sum(X[:, :3], axis=1) > 1).astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n",
        "X_train_encrypted = [ts.ckks_vector(context, x) for x in X_train]\n",
        "X_test_encrypted = [ts.ckks_vector(context, x) for x in X_test]"
      ],
      "metadata": {
        "id": "7IMSvCOW9f3_"
      },
      "id": "7IMSvCOW9f3_",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = EncryptedPerceptron(context, learning_rate=0.1, n_iters=100, n_features=10)\n",
        "p.fit(X_train_encrypted, y_train)\n",
        "#Takes about 5 minutes to train"
      ],
      "metadata": {
        "id": "jBFZy3pr-J6e"
      },
      "id": "jBFZy3pr-J6e",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = p.predict(X_test_encrypted)\n",
        "print(\"Model predictions:\", predictions)\n",
        "print(\"Actual labels:\", y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV6tUQCG-T9s",
        "outputId": "be6741a7-c4d1-4f03-f9e2-3dadef63a4e4"
      },
      "id": "bV6tUQCG-T9s",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model predictions: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0]\n",
            "Actual labels: [0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy = np.mean(predictions == y_test)\n",
        "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCsUhlpe_09w",
        "outputId": "bab19eab-b82f-4fe4-d7ad-69363d920d2e"
      },
      "id": "kCsUhlpe_09w",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 100.00%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}